{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eeg_model1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "407h2wSphg2V"
      },
      "source": [
        "# 텐서플로 2 버전 선택\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNhCezPxh1mp"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split #데이터셋을 나누는 함수\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80UVwJXqh4J4"
      },
      "source": [
        "#데이터 불러오기\n",
        "x = np.load(\"/content/drive/My Drive/numpy_data/savedfp1_x_z.npy\")  #saved2_x.npy, saved3_x.npy\n",
        "y = np.load(\"/content/drive/My Drive/numpy_data/saved_y.npy\")  #saved2_y.npy, saved3_y.npy\n",
        "x_list = np.array(x)\n",
        "y_list = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvUnhA7nh5gA"
      },
      "source": [
        "# 데이터 분리하기\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_list, y_list, test_size=0.2, stratify=y_list) #0.2\n",
        "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5, stratify=Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUql6H0pk_E5",
        "outputId": "96dae35f-e2f6-4392-aea8-decc9ed8a8f7"
      },
      "source": [
        "print(np.shape(X_train))\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(X_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(87, 210000)\n",
            "(11, 210000)\n",
            "(11, 210000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcTsDdsmkbpJ"
      },
      "source": [
        "X_train = np.reshape(X_train, (87, 500, 420)) #(87, 500, 420)\n",
        "X_test = np.reshape(X_test, (11, 500, 420)) #(11, 500, 420)\n",
        "X_val = np.reshape(X_val, (11, 500, 420)) #(11, 500, 420)\n",
        "Y_train = np.reshape(Y_train, (87, 1))\n",
        "Y_test = np.reshape(Y_test, (11, 1))\n",
        "Y_val = np.reshape(Y_val, (11, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cww2no_OiVqa",
        "outputId": "aefb4171-4a9a-4831-f6f6-f599c72e5c9b"
      },
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(128, 5, strides=1, input_shape=(500, 420), activation='relu'), #128, 7, 1, (64, 210000)\n",
        "    tf.keras.layers.MaxPooling1D(2, strides=2), #tf.keras.layers.MaxPooling1D(2, strides=2)\n",
        "    tf.keras.layers.Conv1D(64, 5, strides=2, activation='relu'), #64, 5, 2\n",
        "    tf.keras.layers.MaxPooling1D(2, strides=2), #tf.keras.layers.MaxPooling1D(2, strides=2)\n",
        "    tf.keras.layers.Conv1D(32, 3, strides=1, activation='relu'), #32, 3, 1\n",
        "    tf.keras.layers.MaxPooling1D(2, strides=2), #2, 2\n",
        "    tf.keras.layers.LSTM(units=32, return_sequences=True), #32\n",
        "    tf.keras.layers.LSTM(units=32, return_sequences=True), #32\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=10, activation='relu'), #10\n",
        "    tf.keras.layers.Dropout(rate=0.2), #0.2\n",
        "    tf.keras.layers.Dense(units=2, activation='softmax') #2\n",
        "])\n",
        "\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Accuracy()]) #binary_crossentropy\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_28 (Conv1D)           (None, 496, 128)          268928    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_27 (MaxPooling (None, 248, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_29 (Conv1D)           (None, 122, 64)           41024     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 61, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, 59, 32)            6176      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 29, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 29, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 29, 32)            8320      \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 928)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                9290      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 342,080\n",
            "Trainable params: 342,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdb45NZjoSpy",
        "outputId": "f4ddf53a-60fb-4f30-80b0-00175caf5233"
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(units=64, input_shape=(500, 420), return_sequences=True), #32\n",
        "    tf.keras.layers.LSTM(units=32, return_sequences=True), #32\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=10, activation='LeakyReLU'), #10\n",
        "    tf.keras.layers.Dropout(rate=0.2), #0.2\n",
        "    tf.keras.layers.Dense(units=2, activation='softmax') #2\n",
        "])\n",
        "\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Accuracy()]) #binary_crossentropy\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_51 (LSTM)               (None, 500, 64)           124160    \n",
            "_________________________________________________________________\n",
            "lstm_52 (LSTM)               (None, 500, 32)           12416     \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 10)                160010    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 296,608\n",
            "Trainable params: 296,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWMQVUq_ifoQ"
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=17, batch_size=64, validation_data=(X_val, Y_val)) #epoch=17 batch_size=64\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['sparse_categorical_accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIVuqdmivKA"
      },
      "source": [
        "# 테스트 정확도 출력\n",
        "#print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"정답률: \", score[1], \"loss: \", score[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq781H232Hir"
      },
      "source": [
        "test_p = model.predict(X_train)\n",
        "print(Y_train.flatten())\n",
        "print(test_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ynFYVLK6YT0"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "xp, a = make_regression(n_samples=11, n_features=2, noise=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}